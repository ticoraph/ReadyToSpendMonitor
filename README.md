# ReadyToSpendMonitor

Mise en production d'un modÃ¨le de scoring pour l'entreprise "PrÃªt Ã  DÃ©penser".

Ce projet inclut la crÃ©ation d'une API robuste, la conteneurisation pour un dÃ©ploiement fluide, et la mise en place d'un monitoring proactif pour garantir la performance et la fiabilitÃ© du modÃ¨le dans le temps.

## ðŸ“‹ Contenu

- API FastAPI pour les prÃ©dictions de scoring
- Conteneurisation Docker
- Pipeline CI/CD (GitHub Actions)
- Tests automatisÃ©s
- Monitoring et dÃ©tection du data drift
- Dashboard Streamlit

## ðŸ—ï¸ Structure du projet

```
ReadyToSpendMonitor/
â”œâ”€â”€ src/                    # Code source
â”‚   â”œâ”€â”€ api/               # API FastAPI
â”‚   â”œâ”€â”€ models/            # ModÃ¨le et logique d'infÃ©rence
â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â””â”€â”€ logger.py          # Logging
â”œâ”€â”€ tests/                 # Tests unitaires
â”œâ”€â”€ notebooks/             # Notebooks d'analyse
â”œâ”€â”€ models/                # Artefacts du modÃ¨le
â”œâ”€â”€ data/                  # DonnÃ©es de rÃ©fÃ©rence
â”œâ”€â”€ logs/                  # Logs de production
â”œâ”€â”€ docker/                # Configuration Docker
â”œâ”€â”€ .github/workflows/     # Pipeline CI/CD
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ðŸš€ Installation

### PrÃ©requis

- Python 3.11+
- Docker
- Git

### Installation locale

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/votre-username/ReadyToSpendMonitor.git
cd ReadyToSpendMonitor

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer l'environnement (optionnel)
cp .env.example .env
```

### Installation du modÃ¨le

Placez votre fichier de modÃ¨le entraÃ®nÃ© dans le rÃ©pertoire `models/` avec le nom `scoring_model.pkl`.

## ðŸƒ Lancer l'API

### En local

```bash
# Lancer l'API avec uvicorn
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
```

L'API sera accessible sur http://localhost:8000

- Documentation Swagger: http://localhost:8000/docs
- Endpoint de santÃ©: http://localhost:8000/health

### Avec Docker

```bash
# Construire l'image Docker
docker build -t scoring-api .

# Lancer le conteneur
docker run -p 8000:8000 -v $(pwd)/models:/app/models scoring-api
```

### Avec Docker Compose

```bash
cd docker
docker-compose up -d
```

## ðŸ§ª ExÃ©cuter les tests

```bash
# ExÃ©cuter tous les tests
pytest

# ExÃ©cuter avec couverture
pytest --cov=src --cov-report=html

# ExÃ©cuter un test spÃ©cifique
pytest tests/test_api.py -v
```

## ðŸ“Š Monitoring

### Dashboard Streamlit

```bash
streamlit run notebooks/dashboard.py
```

Le dashboard affiche :
- Distribution des scores prÃ©dits
- Latence de l'API
- Temps d'infÃ©rence
- Analyse du data drift

### Logs

Les logs sont stockÃ©s dans `logs/` :
- `api.log`: Logs de l'API
- `predictions.csv`: DonnÃ©es des prÃ©dictions pour l'analyse du drift

## ðŸ”„ Pipeline CI/CD

Le pipeline GitHub Actions automatise :
1. ExÃ©cution des tests Ã  chaque push
2. Construction de l'image Docker
3. DÃ©ploiement sur la branche main

## ðŸ“ InterprÃ©tation du monitoring

### Distribution des scores
- **Score 0**: Client Ã  faible risque
- **Score 1**: Client Ã  haut risque

### MÃ©triques clÃ©s
| MÃ©trique | Description | Seuil d'alerte |
|----------|-------------|----------------|
| Latence | Temps de rÃ©ponse de l'API | > 500ms |
| Temps d'infÃ©rence | Temps de calcul du modÃ¨le | > 100ms |
| Taux d'erreur | RequÃªtes en Ã©chec | > 5% |
| Drift | Ã‰cart distribution des donnÃ©es | > 0.3 |

## ðŸ”§ Configuration

La configuration se fait via variables d'environnement ou fichier `.env` :

```bash
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO
MODEL_PATH=models
```

## ðŸ“š Documentation

- [Documentation FastAPI](https://fastapi.tiangolo.com/)
- [Documentation Docker](https://docs.docker.com/)
- [Documentation Evidently](https://docs.evidentlyai.com/)