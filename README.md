# PrÃªt Ã  DÃ©penser - MLOps Scoring API

## ğŸ“‹ Description du Projet

Projet de mise en production d'un modÃ¨le de scoring de crÃ©dit pour l'entreprise "PrÃªt Ã  DÃ©penser". Ce projet dÃ©montre une implÃ©mentation complÃ¨te MLOps incluant :

- âœ… API REST avec FastAPI
- âœ… Conteneurisation Docker
- âœ… Pipeline CI/CD avec GitHub Actions
- âœ… Monitoring et dÃ©tection de drift avec Streamlit
- âœ… Tests unitaires automatisÃ©s
- âœ… DÃ©ploiement sur Docker HUB

## ğŸ—ï¸ Architecture du Projet

```
ReadyToSpendMonitor/
â”œâ”€â”€ api/                    # Code de l'API FastAPI
â”‚   â”œâ”€â”€ main.py            # Point d'entrÃ©e de l'API
â”‚   â””â”€â”€ schemas.py         # SchÃ©mas de validation
â”œâ”€â”€ models/                 # ModÃ¨les ML et artefacts
â”‚   â””â”€â”€ model.pkl          # ModÃ¨le entraÃ®nÃ© (Ã  ajouter)
â”œâ”€â”€ monitoring/            # Dashboard de monitoring
â”‚   â””â”€â”€ app.py            # Application Streamlit
â”œâ”€â”€ tests/                 # Tests unitaires
â”‚   â””â”€â”€ test_api.py       # Tests de l'API
â”‚   â””â”€â”€ test_app.py       # Tests de l'APP monitoring
â”œâ”€â”€ notebooks/             # Notebooks d'analyse
â”‚   â””â”€â”€ drift_analysis.ipynb
â”œâ”€â”€ scripts/               # Scripts utilitaires
â”‚   â””â”€â”€ train_model.py    # EntraÃ®nement du modÃ¨le
â”‚   â””â”€â”€ predict_data_from_dataset_thread.py    # Predictions sur un dataset
â”œâ”€â”€ .github/workflows/     # CI/CD
â”‚   â””â”€â”€ ci-cd.yml        # Pipeline GitHub Actions
â”œâ”€â”€ Dockerfile            # Configuration Docker
â”œâ”€â”€ requirements.txt      # DÃ©pendances Python
â””â”€â”€ .gitignore           # Fichiers Ã  ignorer
```

## ğŸš€ Installation et Lancement

### PrÃ©requis
- Python 3.10+
- Docker
- Git

### Installation Locale

```bash
# Cloner le repository
git clone https://github.com/ticoraph/ReadyToSpendMonitor.git
cd ReadyToSpendMonitor

# CrÃ©er un environnement virtuel
python3.10 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Ajouter vos donnÃ©es et modÃ¨le
# - Copier votre modÃ¨le dans models/model.pkl
```

### Lancement de l'API

```bash
# Uvicorn
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000

# L'API sera accessible sur http://localhost:8000
# Documentation interactive : http://localhost:8000/docs
```

### Lancement du Dashboard de Monitoring

```bash
# Dans un nouveau terminal
streamlit run monitoring/app.py

# Le dashboard sera accessible sur http://localhost:8501
```

### Lancement avec Docker

```bash
# Construire l'image
docker build -t readytospendmonitor .
# Executer
docker run -p 8000:8000 -p 8501:8501 -v ./logs:/app/logs readytospendmonitor

```

## ğŸ“Š Utilisation de l'API

### Exemple de requÃªte avec curl

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
  "ACTIVE_AMT_CREDIT_MAX_OVERDUE_MEAN": 7195.5,
  "ACTIVE_AMT_CREDIT_SUM_MAX": 450000,
  "ACTIVE_DAYS_CREDIT_MAX": -753,
  "AMT_ANNUITY": 10548,
  "AMT_CREDIT": 148365,
  "AMT_GOODS_PRICE": 135000,
  "ANNUITY_INCOME_PERC": 0.1019130434782608,
  "APPROVED_AMT_ANNUITY_MEAN": 6340.785,
  "APPROVED_CNT_PAYMENT_MEAN": 14.666666666666666,
  "APPROVED_DAYS_DECISION_MAX": -348,
  "BURO_AMT_CREDIT_MAX_OVERDUE_MEAN": 7195.5,
  "BURO_AMT_CREDIT_SUM_DEBT_MEAN": 0,
  "BURO_DAYS_CREDIT_MAX": -753,
  "BURO_DAYS_CREDIT_MEAN": -979.6666666666666,
  "CC_CNT_DRAWINGS_ATM_CURRENT_MEAN": 0.2666666666666666,
  "CLOSED_AMT_CREDIT_SUM_MAX": 38650.5,
  "CLOSED_DAYS_CREDIT_ENDDATE_MAX": -943,
  "CLOSED_DAYS_CREDIT_MAX": -1065,
  "CLOSED_DAYS_CREDIT_VAR": 256328,
  "CODE_GENDER": 1,
  "DAYS_BIRTH": -11716,
  "DAYS_EMPLOYED": -449,
  "DAYS_EMPLOYED_PERC": 0.0383236599522021,
  "DAYS_ID_PUBLISH": -3961,
  "DAYS_LAST_PHONE_CHANGE": -1420,
  "DAYS_REGISTRATION": -3997,
  "EXT_SOURCE_1": 0.3608707365728421,
  "EXT_SOURCE_2": 0.4285392216965799,
  "EXT_SOURCE_3": 0.7981372313187245,
  "INSTAL_AMT_PAYMENT_MEAN": 10274.82081081081,
  "INSTAL_AMT_PAYMENT_MIN": 2.7,
  "INSTAL_AMT_PAYMENT_SUM": 380168.37,
  "INSTAL_DBD_MAX": 60,
  "INSTAL_DBD_SUM": 833,
  "INSTAL_DPD_MEAN": 0.4594594594594595,
  "INSTAL_PAYMENT_PERC_MEAN": 0.945945945945946,
  "OWN_CAR_AGE": 9,
  "PAYMENT_RATE": 0.0710949347892023,
  "POS_MONTHS_BALANCE_SIZE": 40,
  "PREV_CNT_PAYMENT_MEAN": 15.142857142857142
}'
```

### Exemple de rÃ©ponse

```json
{
  "client_id": "req_20260205103137658530",
  "confidence": 0.8117,
  "decision": "REJECTED",
  "inference_time_ms": 9.67,
  "score": 0.1883
}
```

### Points de terminaison disponibles

- `GET /health` : VÃ©rification de santÃ© de l'API
- `POST /predict` : PrÃ©diction de score
- `POST /predict_batch` : PrÃ©diction de scores en parallÃ¨le sur un batch de donnÃ©es
- `GET /docs` : Documentation Swagger interactive

## ğŸ§ª Tests

```bash
# Lancer tous les tests
pytest -v

# Lancer avec couverture
pytest tests/ --cov-report=html
```

## ğŸ“ˆ Monitoring

Le dashboard Streamlit affiche :

1. **MÃ©triques en temps rÃ©el**
   - Nombre de prÃ©dictions
   - Temps d'infÃ©rence moyen
   - Distribution des scores

2. **DÃ©tection de Data Drift**
   - Comparaison distributions (rÃ©fÃ©rence vs production)
   - Tests statistiques (KS, Chi2)
   - Alertes automatiques

3. **Performance opÃ©rationnelle**
   - Latence de l'API
   - Taux d'erreur
   - Logs rÃ©cents

## ğŸ”„ Pipeline CI/CD

Le pipeline GitHub Actions s'exÃ©cute automatiquement Ã  chaque push sur `main` :

1. âœ… Installation des dÃ©pendances
2. âœ… ExÃ©cution des tests unitaires
3. âœ… Construction de l'image Docker
4. âœ… DÃ©ploiement sur Docker HUB

### Configuration requise

Ajouter ces secrets dans GitHub Settings > Actions secrets and variables > Repository secrets :

- `DOCKERHUB_TOKEN` : Docker HUB Token

## ğŸ” Data Drift Analysis

Le notebook `notebooks/drift_analysis.ipynb` contient :

- Analyse comparative des distributions
- Tests statistiques (Kolmogorov-Smirnov, Chi-Square)
- Visualisations des drifts

## âš¡ Optimisations ImplÃ©mentÃ©es

1. **Chargement du modÃ¨le au dÃ©marrage**
2. **Validation des entrÃ©es** avec Pydantic
3. **Logging structurÃ©** en JSON
4. **Gestion d'erreurs robuste**
5. **Cache des prÃ©dictions**

## ğŸ“ Structure des Logs

Les logs de production contiennent :

```json
{
{"timestamp": "2026-02-11T10:26:19.138831", 
"input": {}, 
"output": {"client_id": "req_20260211102619138813", "score": 0.0929, "decision": "REJECTED", "confidence": 0.1339, "inference_time_ms": 0.9}, 
"model_version": "1.0.0"}
}
```

## ğŸ›¡ï¸ SÃ©curitÃ©

- Validation stricte des entrÃ©es
- Gestion des secrets avec variables d'environnement
- Pas de donnÃ©es sensibles dans les logs
- Rate limiting (Ã  implÃ©menter en production)

## ğŸ¤ Contribution

Ce projet est un travail acadÃ©mique pour la formation Data Science.

## ğŸ“„ Licence

MIT License

## ğŸ‘¤ Auteur

RaphaÃ«l Montico - Data Scientist @ PrÃªt Ã  DÃ©penser (Projet AcadÃ©mique)

## ğŸ™ Remerciements

- OpenClassrooms

---

**Note** : Ce projet est Ã  des fins Ã©ducatives dans le cadre d'une formation MLOps.
