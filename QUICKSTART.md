# ðŸš€ Guide de DÃ©marrage Rapide

## Installation en 5 minutes

### 1. Cloner le projet
```bash
git clone https://github.com/votre-username/pret-a-depenser-mlops.git
cd pret-a-depenser-mlops
```

### 2. CrÃ©er l'environnement virtuel
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. Ajouter vos donnÃ©es et modÃ¨le

**Option A: Utiliser vos propres donnÃ©es**
```bash
# Copier votre modÃ¨le entraÃ®nÃ©
cp /chemin/vers/votre/model.pkl models/

# Copier vos donnÃ©es de rÃ©fÃ©rence
cp /chemin/vers/vos/donnees.csv data/reference_data.csv
```

**Option B: GÃ©nÃ©rer des donnÃ©es de dÃ©monstration**
```bash
python scripts/train_model.py
```

### 5. Lancer l'API
```bash
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

âœ… L'API est maintenant accessible sur http://localhost:8000

### 6. Tester l'API
```bash
# Dans un nouveau terminal
python scripts/test_api.py
```

### 7. Lancer le Dashboard de Monitoring
```bash
# Dans un nouveau terminal
streamlit run monitoring/app.py
```

âœ… Le dashboard est accessible sur http://localhost:8501

---

## DÃ©marrage avec Docker (encore plus simple!)

### 1. PrÃ©parer les donnÃ©es
```bash
python scripts/train_model.py
```

### 2. Lancer avec Docker Compose
```bash
docker-compose up --build
```

âœ… C'est tout! Les services sont maintenant actifs:
- API: http://localhost:8000
- Monitoring: http://localhost:8501

---

## Exemple d'utilisation de l'API

### Avec curl
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "age": 35,
    "income": 50000,
    "loan_amount": 15000,
    "employment_length": 5,
    "credit_score": 720
  }'
```

### Avec Python
```python
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={
        "age": 35,
        "income": 50000,
        "loan_amount": 15000,
        "employment_length": 5,
        "credit_score": 720
    }
)

print(response.json())
```

### RÃ©ponse attendue
```json
{
  "client_id": "req_20250202143500123",
  "score": 0.78,
  "decision": "APPROVED",
  "confidence": 0.85,
  "inference_time_ms": 15.3
}
```

---

## Documentation Interactive

AccÃ©dez Ã  la documentation Swagger automatique:
ðŸ‘‰ http://localhost:8000/docs

---

## RÃ©solution de problÃ¨mes

### ProblÃ¨me: "ModuleNotFoundError: No module named 'api'"
**Solution:** Assurez-vous d'Ãªtre dans le bon dossier et que l'environnement virtuel est activÃ©.

### ProblÃ¨me: "Model not found"
**Solution:** Lancez `python scripts/train_model.py` pour crÃ©er un modÃ¨le de dÃ©monstration.

### ProblÃ¨me: Port 8000 dÃ©jÃ  utilisÃ©
**Solution:** 
```bash
# Changez le port
uvicorn api.main:app --port 8001

# Ou tuez le processus existant
lsof -ti:8000 | xargs kill -9  # Linux/Mac
```

### ProblÃ¨me: Streamlit ne se lance pas
**Solution:** VÃ©rifiez que scipy est installÃ©:
```bash
pip install scipy
```

---

## Structure du Projet (RÃ©sumÃ©)

```
pret-a-depenser-mlops/
â”œâ”€â”€ api/                    # Code de l'API FastAPI
â”œâ”€â”€ models/                 # ModÃ¨le ML (ajoutez le vÃ´tre ici)
â”œâ”€â”€ data/                   # DonnÃ©es (ajoutez les vÃ´tres ici)
â”œâ”€â”€ monitoring/             # Dashboard Streamlit
â”œâ”€â”€ tests/                  # Tests unitaires
â”œâ”€â”€ scripts/                # Scripts utilitaires
â”œâ”€â”€ Dockerfile             # Configuration Docker
â””â”€â”€ requirements.txt       # DÃ©pendances
```

---

## Prochaines Ã‰tapes

1. âœ… Remplacez le modÃ¨le de dÃ©mo par votre vrai modÃ¨le
2. âœ… Ajoutez vos vraies donnÃ©es de rÃ©fÃ©rence
3. âœ… Configurez GitHub Actions (ajoutez HF_TOKEN si besoin)
4. âœ… DÃ©ployez sur Hugging Face Spaces
5. âœ… Analysez le drift avec le notebook `notebooks/drift_analysis.ipynb`

---

## Support

Pour toute question, consultez le README principal ou le notebook d'analyse.

ðŸŽ‰ **Bonne chance avec votre projet MLOps!**
